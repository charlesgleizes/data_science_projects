{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf8a7ee-a443-4ff5-88c8-b33cd404f78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42675a1-f446-48db-b399-259b1fb3fc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pydot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b9bb5a-e5f8-4991-b89c-3b80f9bb8214",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = '/home/jovyan/hfactory_magic_folders/tooling_for_the_data_scientist/deepfakes_detection/images'\n",
    "root = '/home/jovyan/hfactory_magic_folders/tooling_for_the_data_scientist/deepfakes_detection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad59b6c-93c9-4d74-b2a7-360f9c73e64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(root + '/train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fef125-d317-48d0-b5c4-a2b328bcc567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the images between fake and not in two folders\n",
    "# Real images\n",
    "#for id in tqdm(train[train.label==0].image_id):\n",
    "#    im = Image.open(f'{root}/images/{id}.jpg')\n",
    "#    im.save(f'train/real_images/{id}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65b95ee-f62f-46cc-8b50-3c120b20abc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fake images\n",
    "#for id in tqdm(train[train.label==1].image_id):\n",
    "#    im = Image.open(f'{root}/images/{id}.jpg')\n",
    "#    im.save(f'train/fake_images/{id}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbaac8d-0e74-473a-89b2-154b41a46e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(root + '/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cfd0ae-d3fd-433d-b4f2-3c721d98a340",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379c569a-375c-460d-b302-63f1bed19998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "test = pd.read_csv(root + '/test.csv')\n",
    "\n",
    "for id in tqdm(test.image_id):\n",
    "    im = Image.open(f'{root}/images/{id}.jpg')\n",
    "    im.save(f'/home/jovyan/hfactory_magic_folders/tooling_for_the_data_scientist/group_shared_workspace/hufflepuff_project/validation/valid_images/{id}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbed03a6-b99f-4869-a539-ca7490494e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612a45ea-caf4-4754-ad73-98e5a72df68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "a = pd.read_csv('/home/jovyan/group4-deepfakes-detection/results/results.csv')\n",
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e826c4-66d1-47ef-8b97-5a381d076225",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.label = (a.label>.5)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98363c44-183b-4a63-9bfc-662f9d24f07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.shape)\n",
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857842ad-5a4f-41b7-889e-6fa5873c0053",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e9f118-ae8c-4a76-b179-b5b760eabea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(a==b).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1d2dfe-8db3-4755-abd0-d7982bb28061",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.read_csv('sample_submission.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340b47bf-4b97-4b2b-85d8-d6546b8a1c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b.shape)\n",
    "b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe11de8-5187-4a14-a832-f67d214a2d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.to_csv('results2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2295e717-abee-4bfd-8890-1ae4e49bd606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/jovyan/group4-deepfakes-detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18c88cf-69d6-4bdc-9d87-3a65786cdf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b209c506-b09d-45fe-b1ff-7b6cc7322876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/jovyan/group4-deepfakes-detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1c3fc8-2c87-49f9-b2b4-48df5ed2d54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.deepfake_reco import *\n",
    "\n",
    "with open('/home/jovyan/group4-deepfakes-detection/config.yaml', 'rb') as f:\n",
    "    conf = yaml.safe_load(f.read()) \n",
    "\n",
    "image_size = tuple(conf.get('IMAGE_SIZE'))\n",
    "batch_size = conf.get('BATCH_SIZE')\n",
    "n_epochs = conf.get('N_EPOCHS')\n",
    "train_test_path = conf.get('TRAIN_TEST_PATH')\n",
    "eval_path = conf.get('EVAL_PATH')\n",
    "eval_id_path = conf.get('EVAL_ID_PATH')\n",
    "\n",
    "# Pipeline start\n",
    "# Dataset\n",
    "train_ds, test_ds, eval_ds = data_generation(image_size, batch_size, train_test_path, eval_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ede86b-31b9-47ff-b346-1c0ecbf51164",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a664907-bd73-48ba-ba9a-82d4e269c1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/home/jovyan/hfactory_magic_folders/tooling_for_the_data_scientist/group_shared_workspace/hufflepuff_project/test/'\n",
    "test_ds = tfds.folder_dataset.ImageFolder(folder_path, *, (180, 180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0c1fbf-51f3-4b57-abe0-5573c16425bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (180, 180)\n",
    "batch_size = 32\n",
    "train_path = '/home/jovyan/hfactory_magic_folders/tooling_for_the_data_scientist/group_shared_workspace/hufflepuff_project/train'\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_path,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_path,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9266c37-a486-4079-a6f8-88381b435609",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_path = '/home/jovyan/hfactory_magic_folders/tooling_for_the_data_scientist/group_shared_workspace/hufflepuff_project/val'\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    valid_path,\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cba459c-2ae7-4c8d-945b-6ca0aed57c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open('/home/jovyan/group4-deepfakes-detection/config.yaml', 'rb') as f:\n",
    "    conf = yaml.safe_load(f.read()) \n",
    "conf.get('TRAIN_TEST_PATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1d3ebe-2d3f-44a9-892a-c20345d4bd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf.get('TRAIN_TEST_PATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88316fd4-d5f7-4560-aa24-098df6f5584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7079f929-bb22-4b29-98a3-4c38ba9b71b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(int(labels[i]))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30e28c9-ea1d-4f15-8cae-c19f324d7bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.prefetch(buffer_size=32)\n",
    "val_ds = val_ds.prefetch(buffer_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d884147e-dcf4-40e9-981d-ee0eab3ec846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    # Image augmentation block\n",
    "    #x = data_augmentation(inputs)\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [128, 256, 512, 728]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        activation = \"sigmoid\"\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = \"softmax\"\n",
    "        units = num_classes\n",
    "\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(units, activation=activation)(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa09454-39a3-4094-8de5-9c93244f7789",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv('/home/jovyan/group4-deepfakes-detection/sample_submission.csv')\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f77230d-c0da-4467-aadd-a6d2d0ecb6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model(input_shape=image_size + (3,), num_classes=2)\n",
    "#keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8f5b66-a82b-4359-968b-9c91cf240fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(\n",
    "    train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a72c67-f13d-45d5-ad6c-e4056ab3749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46c9fbe-3f5c-4560-a6cb-848891100195",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
